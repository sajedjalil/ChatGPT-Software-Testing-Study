{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RQ1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: /Users/sajed/PycharmProjects/Study-on-ChatGPT/dataset/code vs conceptual\n"
     ]
    }
   ],
   "source": [
    "base_folder_path = os.getcwd().split(os.sep + 'src')[0]\n",
    "dataset_path = os.path.join(base_folder_path, 'dataset', 'code vs conceptual')\n",
    "print(\"Dataset Path: \" + dataset_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def find_tag_dict_answer(df:pd.DataFrame, counter):\n",
    "\n",
    "    tags = [\"AC\", \"AIC\", \"APC\"]\n",
    "    tag_dict = dict()\n",
    "    for tag in tags:\n",
    "        tag_dict[tag] = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Answer.'+str(counter)] not in tags:\n",
    "            continue\n",
    "\n",
    "        tag_dict[row['Answer.'+str(counter)]] += 1\n",
    "\n",
    "    return tag_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def find_tag_dict_explanation(df:pd.DataFrame, counter):\n",
    "\n",
    "    tags = [\"EC\", \"EIC\", \"EPC\"]\n",
    "    tag_dict = dict()\n",
    "    for tag in tags:\n",
    "        tag_dict[tag] = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Explanation.'+str(counter)] not in tags:\n",
    "            continue\n",
    "\n",
    "        tag_dict[row['Explanation.'+str(counter)]] += 1\n",
    "\n",
    "    return tag_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: all\n",
      "            AC  AIC  APC\n",
      "shared_1     7    9    0\n",
      "shared_2     7    8    1\n",
      "shared_3     8    7    1\n",
      "separate_1   1   14    1\n",
      "separate_2   4   11    1\n",
      "separate_3   5   10    1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/4172211252.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_ans = result_ans.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/4172211252.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_ans = result_ans.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/4172211252.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_ans = result_ans.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/4172211252.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_ans = result_ans.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/4172211252.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_ans = result_ans.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/4172211252.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_ans = result_ans.append( pd.DataFrame( [tag_dict]) )\n"
     ]
    }
   ],
   "source": [
    "xlsx_file_path = dataset_path + os.sep + \"combined_pair_code.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_pair_conceptual.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_pair_combined.xlsx\"\n",
    "sheets = pd.ExcelFile(os.path.join(xlsx_file_path)).sheet_names\n",
    "total_iterations = 3\n",
    "\n",
    "for sheet in sheets:\n",
    "    df = pd.read_excel(xlsx_file_path, sheet)\n",
    "    print( \"Sheet:\", sheet)\n",
    "\n",
    "    result_ans = pd.DataFrame()\n",
    "    for index in range(1, (total_iterations*2)+1):\n",
    "        tag_dict = find_tag_dict_answer(df, index)\n",
    "        result_ans = result_ans.append( pd.DataFrame( [tag_dict]) )\n",
    "\n",
    "    index_column = pd.Index(['shared_1', 'shared_2', 'shared_3', 'separate_1', 'separate_2', 'separate_3'])\n",
    "    result_ans = result_ans.set_index(index_column)\n",
    "    print(result_ans)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: all\n",
      "            EC  EIC  EPC\n",
      "shared_1     5   10    1\n",
      "shared_2     5   10    1\n",
      "shared_3     5    9    2\n",
      "separate_1   1   14    1\n",
      "separate_2   3   12    1\n",
      "separate_3   4   11    1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/1557851308.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_exp = result_exp.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/1557851308.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_exp = result_exp.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/1557851308.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_exp = result_exp.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/1557851308.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_exp = result_exp.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/1557851308.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_exp = result_exp.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/1557851308.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_exp = result_exp.append( pd.DataFrame( [tag_dict]) )\n"
     ]
    }
   ],
   "source": [
    "for sheet in sheets:\n",
    "    df = pd.read_excel(xlsx_file_path, sheet)\n",
    "    print( \"Sheet:\", sheet)\n",
    "\n",
    "    result_exp = pd.DataFrame()\n",
    "    for index in range(1, (total_iterations*2)+1):\n",
    "        tag_dict = find_tag_dict_explanation(df, index)\n",
    "        result_exp = result_exp.append( pd.DataFrame( [tag_dict]) )\n",
    "\n",
    "    index_column = pd.Index(['shared_1', 'shared_2', 'shared_3', 'separate_1', 'separate_2', 'separate_3'])\n",
    "    result_exp = result_exp.set_index(index_column)\n",
    "    print(result_exp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RQ2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "xlsx_file_path = dataset_path + os.sep + \"combined_merged_code.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_merged_conceptual.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_merged_combined.xlsx\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def find_response_type_dict(df:pd.DataFrame, counter):\n",
    "    tag_dict = dict()\n",
    "    explanations = [\"EC\", \"EIC\", \"EPC\"]\n",
    "    answers = ['AC', 'AIC', 'APC']\n",
    "    for tag_1 in explanations:\n",
    "        for tag_2 in answers:\n",
    "            tag_dict[ tag_1 + '-' + tag_2] = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Explanation.'+str(counter)] not in explanations:\n",
    "            continue\n",
    "        if row['Answer.'+str(counter)] not in answers:\n",
    "            continue\n",
    "\n",
    "        key = row['Explanation.'+str(counter)] + '-' + row['Answer.'+str(counter)]\n",
    "\n",
    "        if key in tag_dict:\n",
    "            tag_dict[key] += 1\n",
    "\n",
    "    return tag_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: all\n",
      "          EC-AC  EC-AIC  EC-APC  EIC-AC  EIC-AIC  EIC-APC  EPC-AC  EPC-AIC  \\\n",
      "shared_1      5       0       0       2        8        0       0        1   \n",
      "shared_2      5       0       0       2        8        0       0        0   \n",
      "shared_3      5       0       0       2        7        0       1        0   \n",
      "\n",
      "          EPC-APC  \n",
      "shared_1        0  \n",
      "shared_2        1  \n",
      "shared_3        1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/3371354841.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/3371354841.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append( pd.DataFrame( [tag_dict]) )\n",
      "/var/folders/0j/xlmdg4yd2m3_d3s69ffh30ph0000gn/T/ipykernel_4999/3371354841.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append( pd.DataFrame( [tag_dict]) )\n"
     ]
    }
   ],
   "source": [
    "sheets = pd.ExcelFile(os.path.join(xlsx_file_path)).sheet_names\n",
    "total_iterations = 3\n",
    "sheet = 'all'\n",
    "\n",
    "df = pd.read_excel(xlsx_file_path, sheet)\n",
    "print( \"Sheet:\", sheet)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for index in range(1, total_iterations+1):\n",
    "    tag_dict = find_response_type_dict(df, index)\n",
    "    result = result.append( pd.DataFrame( [tag_dict]) )\n",
    "\n",
    "index_column = pd.Index(['shared_1', 'shared_2', 'shared_3'])\n",
    "result = result.set_index(index_column)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RQ3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "xlsx_file_path = dataset_path + os.sep + \"combined_merged_code.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_merged_conceptual.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_merged_combined.xlsx\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "df = pd.read_excel(xlsx_file_path, 'all')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Inconsistent: 0 Consistent: 6\n"
     ]
    }
   ],
   "source": [
    "consistent = 0\n",
    "inconsistent = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    prev = row['Explanation.1']\n",
    "\n",
    "    if pd.isna(prev):\n",
    "        continue\n",
    "\n",
    "    flag = False\n",
    "\n",
    "    for iter in range(2, 4):\n",
    "        col_name = row['Explanation.'+str(iter)]\n",
    "        if prev is not col_name:\n",
    "            inconsistent += 1\n",
    "            flag = True\n",
    "            break\n",
    "\n",
    "    if flag == False:\n",
    "        consistent += 1\n",
    "\n",
    "print(\"Explanation\", \"Inconsistent:\", inconsistent, \"Consistent:\", consistent)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Inconsistent: 0 Consistent: 6\n"
     ]
    }
   ],
   "source": [
    "consistent = 0\n",
    "inconsistent = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    prev = row['Answer.1']\n",
    "    if pd.isna(prev):\n",
    "        continue\n",
    "\n",
    "    flag = False\n",
    "\n",
    "    for iter in range(2, 4):\n",
    "        col_name = row['Answer.'+str(iter)]\n",
    "        if prev is not col_name:\n",
    "            inconsistent += 1\n",
    "            flag = True\n",
    "            break\n",
    "\n",
    "    if flag == False:\n",
    "        consistent += 1\n",
    "\n",
    "print(\"Answer\", \"Inconsistent:\", inconsistent, \"Consistent:\", consistent)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RQ4: Confidence analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def find_confidence_dict(df:pd.DataFrame, tags, keyword):\n",
    "    tag_dict = dict()\n",
    "\n",
    "    for tag in tags:\n",
    "        tag_dict[ tag ] = dict()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        if pd.isna(row['Confidence.2']):\n",
    "            key = row[keyword+'.1']\n",
    "            if key in tag_dict:\n",
    "                if row['Confidence.1'] not in tag_dict[key]:\n",
    "                    tag_dict[key][row['Confidence.1']] = 1\n",
    "                else:\n",
    "                    tag_dict[key][row['Confidence.1']] += 1\n",
    "        else:\n",
    "            key = row[keyword+'.4']\n",
    "            if key in tag_dict:\n",
    "                if row['Confidence.2'] not in tag_dict[key]:\n",
    "                    tag_dict[key][row['Confidence.2']] = 1\n",
    "                else:\n",
    "                    tag_dict[key][row['Confidence.2']] += 1\n",
    "\n",
    "    return tag_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "xlsx_file_path = dataset_path + os.sep + \"combined_pair_code.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_pair_conceptual.xlsx\"\n",
    "# xlsx_file_path = dataset_path + os.sep + \"combined_pair_combined.xlsx\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: all\n",
      "                  AC  AIC  APC\n",
      "Confident          1  0.0  0.0\n",
      "Highly confident   2  0.0  1.0\n",
      "                  EC  EIC  EPC\n",
      "Confident          1  0.0  0.0\n",
      "Highly confident   2  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "sheets = pd.ExcelFile(os.path.join(xlsx_file_path)).sheet_names\n",
    "sheet = 'all'\n",
    "\n",
    "df = pd.read_excel(xlsx_file_path, sheet)\n",
    "print( \"Sheet:\", sheet)\n",
    "\n",
    "\n",
    "tag_dict = find_confidence_dict(df, ['AC', 'AIC', 'APC'], 'Answer')\n",
    "result = pd.DataFrame( tag_dict)\n",
    "result = result. replace(np.nan,0)\n",
    "print(result)\n",
    "\n",
    "\n",
    "tag_dict = find_confidence_dict(df, [\"EC\", \"EIC\", \"EPC\"], 'Explanation')\n",
    "result = pd.DataFrame( tag_dict)\n",
    "result = result. replace(np.nan,0)\n",
    "print(result)\n",
    "\n",
    "    # with pd.ExcelWriter(result_file_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    #     result.to_excel(writer, sheet_name=sheet+\"_confidence\", index=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
